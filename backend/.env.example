# Backend Environment Variables
# Copy this file to .env and update values as needed

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=True

# LLM Provider Settings
# Choose your default provider: ollama, azure-openai, gemini
DEFAULT_PROVIDER=azure-openai
DEFAULT_MODEL=gpt-5-mini

# Ollama Configuration (alternative)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen:7b

# Gemini Configuration
GEMINI_API_KEY=your_api_key_here
GEMINI_MODEL=gemini-1.5-flash

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_MODEL=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# CORS Origins (comma-separated list in JSON array format)
CORS_ORIGINS=["http://localhost:3000"]
