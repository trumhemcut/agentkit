HOST=0.0.0.0
PORT=8000
DEBUG=True

# LLM Provider Settings
DEFAULT_PROVIDER=ollama
DEFAULT_MODEL=qwen:7b

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen:7b

# Gemini Configuration
GEMINI_API_KEY=your_api_key_here
GEMINI_MODEL=gemini-1.5-flash

CORS_ORIGINS=["http://localhost:3000"]
